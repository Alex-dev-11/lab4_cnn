{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea828663-3f5a-4eb4-ba39-7029fde41733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# 1. Импорты и проверка устройства\n",
    "# ================================================================\n",
    "import torch, torchvision, time, onnx, onnxruntime, numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b7c7adc-343a-4989-841a-1ace8a34d44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 2. Преобразования и загрузка CIFAR-10\n",
    "# ================================================================\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_ds = datasets.CIFAR10(root=\"data\", train=True,  download=True, transform=transform)\n",
    "val_ds   = datasets.CIFAR10(root=\"data\", train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True,  num_workers=2)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=32, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d8ba13b-a0c9-4bc2-a04a-b7ed567ee6ad",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sanit\\miniconda3\\envs\\neyro\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Sanit\\miniconda3\\envs\\neyro\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B3_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B3_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# 3. Берём предобученную «сверхточную» модель\n",
    "#    EfficientNet-B3 даёт ≈ 84 % Top-1 на ImageNet → хороший выбор\n",
    "# ================================================================\n",
    "model = torchvision.models.efficientnet_b3(pretrained=True)\n",
    "model.classifier[1] = torch.nn.Linear(model.classifier[1].in_features, 10)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f78ce2d9-eb0f-4f29-bb66-f71f8a2b698d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|█████████████████████████████████████████████████████████| 1563/1563 [03:31<00:00,  7.38it/s, loss=0.511]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1  val-acc=0.963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|█████████████████████████████████████████████████████████| 1563/1563 [03:30<00:00,  7.41it/s, loss=0.218]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2  val-acc=0.962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|████████████████████████████████████████████████████████| 1563/1563 [03:31<00:00,  7.40it/s, loss=0.0348]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3  val-acc=0.960\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm   # pip install tqdm\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)\n",
    "\n",
    "def accuracy(net, loader):\n",
    "    net.eval()\n",
    "    correct = total = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            correct += (net(x).argmax(1) == y).sum().item()\n",
    "            total   += y.size(0)\n",
    "    return correct/total\n",
    "\n",
    "for epoch in range(3):\n",
    "    model.train()\n",
    "    # оборачиваем именно тренировочный loader\n",
    "    with tqdm(train_loader, desc=f\"Epoch {epoch+1}\") as pbar:\n",
    "        for x, y in pbar:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(model(x), y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # обновляем строку прогресса текущим лоссом\n",
    "            pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "    # после эпохи — метрика\n",
    "    print(f\"Epoch {epoch+1}  val-acc={accuracy(model, val_loader):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3df411a8-c3f5-4b24-afbf-14159fdf79f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"test1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49bacfff-7b1d-4f25-b905-4fee7f5aa357",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = torch.load(\"test1.pt\", weights_only = False ,map_location=torch.device(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "147a81f9-4823-4396-8f50-4652874110fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9599\n"
     ]
    }
   ],
   "source": [
    "print(f'accuracy: {accuracy(model1, val_loader)}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7adfa718-0c0b-4e0c-b8d9-4f1e827627e5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 7. Сравнение скорости инференса\n",
    "#    Будем прогонять 1000 батчей по 32 картинки = 32 000 изображений\n",
    "# ================================================================\n",
    "def pytorch_inference_time(net, loader, batches=1000):\n",
    "    net.eval()\n",
    "    torch.cuda.synchronize()\n",
    "    t0 = time.time()\n",
    "    with torch.no_grad():\n",
    "        for i, (x, _) in enumerate(loader):\n",
    "            if i == batches: break\n",
    "            x = x.to(device)\n",
    "            _ = net(x)\n",
    "        torch.cuda.synchronize()\n",
    "    return time.time() - t0\n",
    "\n",
    "def onnx_inference_time(sess, loader, batches=1000):\n",
    "    input_name  = sess.get_inputs()[0].name\n",
    "    torch.cuda.synchronize() if device.type==\"cuda\" else None\n",
    "    t0 = time.time()\n",
    "    for i, (x, _) in enumerate(loader):\n",
    "        if i == batches: break\n",
    "        x = x.numpy()\n",
    "        _ = sess.run(None, {input_name: x})\n",
    "    torch.cuda.synchronize() if device.type==\"cuda\" else None\n",
    "    return time.time() - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "170ca8d5-c800-44a1-bcd4-eb7430e9f883",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch GPU: 17.48 с\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'onnx_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPyTorch GPU: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpytorch_gpu_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m с\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# 7б) ONNX Runtime GPU\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m ort_session_gpu = onnxruntime.InferenceSession(\u001b[43monnx_path\u001b[49m,\n\u001b[32m      7\u001b[39m                 providers=[\u001b[33m\"\u001b[39m\u001b[33mCUDAExecutionProvider\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m      8\u001b[39m onnx_gpu_time = onnx_inference_time(ort_session_gpu, val_loader)\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mONNX  GPU:   \u001b[39m\u001b[38;5;132;01m{\u001b[39;00monnx_gpu_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m с\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'onnx_path' is not defined"
     ]
    }
   ],
   "source": [
    "# 7а) PyTorch\n",
    "pytorch_gpu_time = pytorch_inference_time(model, val_loader)\n",
    "print(f\"PyTorch GPU: {pytorch_gpu_time:.2f} с\")\n",
    "\n",
    "# 7б) ONNX Runtime GPU\n",
    "ort_session_gpu = onnxruntime.InferenceSession(onnx_path,\n",
    "                providers=[\"CUDAExecutionProvider\"])\n",
    "onnx_gpu_time = onnx_inference_time(ort_session_gpu, val_loader)\n",
    "print(f\"ONNX  GPU:   {onnx_gpu_time:.2f} с\")\n",
    "\n",
    "# 7в) ONNX Runtime CPU\n",
    "ort_session_cpu = onnxruntime.InferenceSession(onnx_path,\n",
    "                providers=[\"CPUExecutionProvider\"])\n",
    "onnx_cpu_time = onnx_inference_time(ort_session_cpu, val_loader)\n",
    "print(f\"ONNX  CPU:   {onnx_cpu_time:.2f} с\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab9a8a3f-78fb-4b1d-807f-a4a17899f7c8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Найден dummy_input из CIFAR10 датасета\n",
      "  Форма: torch.Size([1, 3, 224, 224])\n",
      "  Тип: torch.float32\n",
      "  Диапазон значений: [-1.707, 2.570]\n",
      "  Сохранен в 'dummy_input.pt'\n"
     ]
    }
   ],
   "source": [
    "for batch in val_loader:\n",
    "    # batch содержит (inputs, labels)\n",
    "    images, labels = batch\n",
    "    \n",
    "    # Берем первую картинку из батча\n",
    "    dummy_input = images[0:1]  # размер: [1, 3, 224, 224]\n",
    "    \n",
    "    print(f\"✓ Найден dummy_input из CIFAR10 датасета\")\n",
    "    print(f\"  Форма: {dummy_input.shape}\")\n",
    "    print(f\"  Тип: {dummy_input.dtype}\")\n",
    "    print(f\"  Диапазон значений: [{dummy_input.min():.3f}, {dummy_input.max():.3f}]\")\n",
    "    \n",
    "    # Можно сохранить для дальнейшего использования\n",
    "    torch.save(dummy_input, 'dummy_input.pt')\n",
    "    print(f\"  Сохранен в 'dummy_input.pt'\")\n",
    "    \n",
    "    break  # берем только первый батч"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eb7ff22f-4e79-495a-9aaf-3ccd2c07e028",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1202 12:30:25.785000 8708 site-packages\\torch\\onnx\\_internal\\exporter\\_compat.py:114] Setting ONNX exporter to use operator set version 18 because the requested opset_version 11 is a lower version than we have implementations for. Automatic version conversion will be performed, which may not be successful at converting to the requested version. If version conversion is unsuccessful, the opset version of the exported model will be kept at 18. Please consider setting opset_version >=18 to leverage latest ONNX features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Dummy input создан: torch.Size([32, 3, 224, 224])\n",
      "[torch.onnx] Obtain model graph for `EfficientNet([...]` with `torch.export.export(..., strict=False)`...\n",
      "[torch.onnx] Obtain model graph for `EfficientNet([...]` with `torch.export.export(..., strict=False)`... ✅\n",
      "[torch.onnx] Run decomposition...\n",
      "[torch.onnx] Run decomposition... ✅\n",
      "[torch.onnx] Translate the graph into ONNX...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model version conversion is not supported by the onnxscript version converter and fallback is enabled. The model will be converted using the onnx C API (target version: 11).\n",
      "Failed to convert the model to the target version 11 using the ONNX C API. The model was not modified\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sanit\\miniconda3\\envs\\neyro\\Lib\\site-packages\\onnxscript\\version_converter\\__init__.py\", line 127, in call\n",
      "    converted_proto = _c_api_utils.call_onnx_api(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Sanit\\miniconda3\\envs\\neyro\\Lib\\site-packages\\onnxscript\\version_converter\\_c_api_utils.py\", line 65, in call_onnx_api\n",
      "    result = func(proto)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Sanit\\miniconda3\\envs\\neyro\\Lib\\site-packages\\onnxscript\\version_converter\\__init__.py\", line 122, in _partial_convert_version\n",
      "    return onnx.version_converter.convert_version(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Sanit\\miniconda3\\envs\\neyro\\Lib\\site-packages\\onnx\\version_converter.py\", line 39, in convert_version\n",
      "    converted_model_str = C.convert_version(model_str, target_version)\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: D:\\a\\onnx\\onnx\\onnx/version_converter/adapters/axes_input_to_attribute.h:65: adapt: Assertion `node->hasAttribute(kaxes)` failed: No initializer or constant input to node found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Translate the graph into ONNX... ✅\n",
      "Applied 156 of general pattern rewrite rules.\n",
      "\n",
      "✓ Модель экспортирована в: efficientnet_b3_cifar10.onnx\n"
     ]
    }
   ],
   "source": [
    "import torch.onnx\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "# Создаем dummy_input\n",
    "dummy_input = torch.randn(32, 3, 224, 224).to(device)\n",
    "print(f\"✓ Dummy input создан: {dummy_input.shape}\")\n",
    "\n",
    "# Экспорт в ONNX\n",
    "onnx_path = \"efficientnet_b3_cifar10.onnx\"\n",
    "model.eval()\n",
    "torch.onnx.export(\n",
    "    model,                      # модель\n",
    "    dummy_input,                # пример входных данных\n",
    "    onnx_path,                 # путь сохранения\n",
    "    export_params=True,        # сохранять обученные веса\n",
    "    opset_version=11,          # версия ONNX (рекомендуется 11+)\n",
    "    do_constant_folding=True,  # оптимизация констант\n",
    "    input_names=['input'],     # имя входного узла\n",
    "    output_names=['output'],   # имя выходного узла\n",
    "    \n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Модель экспортирована в: {onnx_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "42abc574-1477-4b4f-a01e-253ecde8fbfc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "InvalidArgument",
     "evalue": "[ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Got invalid dimensions for input: input for the following indices\n index: 0 Got: 16 Expected: 32\n Please fix either the inputs/outputs or the model.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInvalidArgument\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 7а) PyTorch\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#pytorch_gpu_time = pytorch_inference_time(model, val_loader) #= 20.51c\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m#print(f\"PyTorch GPU: {pytorch_gpu_time:.2f} с\")\u001b[39;00m\n\u001b[32m      4\u001b[39m \n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# 7б) ONNX Runtime GPU\u001b[39;00m\n\u001b[32m      6\u001b[39m ort_session_gpu = onnxruntime.InferenceSession(onnx_path, \n\u001b[32m      7\u001b[39m                 providers=[\u001b[33m\"\u001b[39m\u001b[33mCUDAExecutionProvider\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m onnx_gpu_time = \u001b[43monnx_inference_time\u001b[49m\u001b[43m(\u001b[49m\u001b[43mort_session_gpu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mONNX  GPU:   \u001b[39m\u001b[38;5;132;01m{\u001b[39;00monnx_gpu_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m с\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;66;03m# 204.60c\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# 7в) ONNX Runtime CPU\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# ort_session_cpu = onnxruntime.InferenceSession(onnx_path,\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m#                providers=[\"CPUExecutionProvider\"])\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# onnx_cpu_time = onnx_inference_time(ort_session_cpu, val_loader)\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# print(f\"ONNX  CPU:   {onnx_cpu_time:.2f} с\") # 210c\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 24\u001b[39m, in \u001b[36monnx_inference_time\u001b[39m\u001b[34m(sess, loader, batches)\u001b[39m\n\u001b[32m     22\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i == batches: \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     23\u001b[39m     x = x.numpy()\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m     _ = \u001b[43msess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m torch.cuda.synchronize() \u001b[38;5;28;01mif\u001b[39;00m device.type==\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m time.time() - t0\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\neyro\\Lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py:287\u001b[39m, in \u001b[36mSession.run\u001b[39m\u001b[34m(self, output_names, input_feed, run_options)\u001b[39m\n\u001b[32m    285\u001b[39m     output_names = [output.name \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._outputs_meta]\n\u001b[32m    286\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_feed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    288\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m C.EPFail \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    289\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._enable_fallback:\n",
      "\u001b[31mInvalidArgument\u001b[39m: [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Got invalid dimensions for input: input for the following indices\n index: 0 Got: 16 Expected: 32\n Please fix either the inputs/outputs or the model."
     ]
    }
   ],
   "source": [
    "# 7а) PyTorch\n",
    "#pytorch_gpu_time = pytorch_inference_time(model, val_loader) #= 20.51c\n",
    "#print(f\"PyTorch GPU: {pytorch_gpu_time:.2f} с\")\n",
    "\n",
    "# 7б) ONNX Runtime GPU\n",
    "ort_session_gpu = onnxruntime.InferenceSession(onnx_path, \n",
    "                providers=[\"CUDAExecutionProvider\"])\n",
    "onnx_gpu_time = onnx_inference_time(ort_session_gpu, val_loader)\n",
    "print(f\"ONNX  GPU:   {onnx_gpu_time:.2f} с\") # 204.60c\n",
    "\n",
    "# 7в) ONNX Runtime CPU\n",
    "# ort_session_cpu = onnxruntime.InferenceSession(onnx_path,\n",
    "#                providers=[\"CPUExecutionProvider\"])\n",
    "# onnx_cpu_time = onnx_inference_time(ort_session_cpu, val_loader)\n",
    "# print(f\"ONNX  CPU:   {onnx_cpu_time:.2f} с\") # 210c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e09675-91bc-482d-9425-bf11a441d840",
   "metadata": {},
   "source": [
    "eFFICIENT b0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1a62508-12af-4169-b54d-ced33bd0d74b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sanit\\miniconda3\\envs\\neyro\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Sanit\\miniconda3\\envs\\neyro\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model_b0 = torchvision.models.efficientnet_b0(pretrained=True)\n",
    "model_b0.classifier[1] = torch.nn.Linear(model_b0.classifier[1].in_features, 10)\n",
    "model_b0 = model_b0.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7072d07-bf9c-4f24-8a11-df78ac324669",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sanit\\miniconda3\\envs\\neyro\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Sanit\\miniconda3\\envs\\neyro\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Epoch 1: 100%|█████████████████████████████████████████████████████████| 1563/1563 [02:00<00:00, 12.93it/s, loss=0.249]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1  val-acc=0.945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|████████████████████████████████████████████████████████| 1563/1563 [02:01<00:00, 12.85it/s, loss=0.0937]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2  val-acc=0.953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████████████████████████████████████████████████████| 1563/1563 [02:01<00:00, 12.83it/s, loss=0.12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3  val-acc=0.952\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# 1. Импорты и проверка устройства\n",
    "# ================================================================\n",
    "import torch, torchvision, time, onnx, onnxruntime, numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "from tqdm import tqdm   # pip install tqdm\n",
    "\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# 2. Преобразования и загрузка CIFAR-10\n",
    "# ================================================================\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_ds = datasets.CIFAR10(root=\"data\", train=True,  download=True, transform=transform)\n",
    "val_ds   = datasets.CIFAR10(root=\"data\", train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True,  num_workers=2)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "model_b0 = torchvision.models.efficientnet_b0(pretrained=True)\n",
    "model_b0.classifier[1] = torch.nn.Linear(model_b0.classifier[1].in_features, 10)\n",
    "model_b0 = model_b0.to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model_b0.parameters(), lr=3e-4)\n",
    "\n",
    "def accuracy(net, loader):\n",
    "    net.eval()\n",
    "    correct = total = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            correct += (net(x).argmax(1) == y).sum().item()\n",
    "            total   += y.size(0)\n",
    "    return correct/total\n",
    "    \n",
    "for epoch in range(3):\n",
    "    model_b0.train()\n",
    "    # оборачиваем именно тренировочный loader\n",
    "    with tqdm(train_loader, desc=f\"Epoch {epoch+1}\") as pbar:\n",
    "        for x, y in pbar:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(model_b0(x), y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # обновляем строку прогресса текущим лоссом\n",
    "            pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "    # после эпохи — метрика\n",
    "    print(f\"Epoch {epoch+1}  val-acc={accuracy(model_b0, val_loader):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fa81c56-863b-4ec5-89b5-9f8b69489718",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## Информация о GPU\n",
      "\n",
      "**Устройство:** NVIDIA GeForce RTX 3070 Ti\n",
      "**VRAM:** 8.59 GB\n",
      "**CUDA доступно:** Да\n",
      "**Текущее устройство:** cuda:0\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "#GPU_INFO\n",
    "# gpu_info.py\n",
    "import torch\n",
    "\n",
    "def get_gpu_info():\n",
    "    if torch.cuda.is_available():\n",
    "        device_name = torch.cuda.get_device_name(0)\n",
    "        vram_gb = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "        \n",
    "        info = f\"\"\"\n",
    "## Информация о GPU\n",
    "\n",
    "**Устройство:** {device_name}\n",
    "**VRAM:** {vram_gb:.2f} GB\n",
    "**CUDA доступно:** Да\n",
    "**Текущее устройство:** cuda:{torch.cuda.current_device()}\n",
    "        \"\"\"\n",
    "    else:\n",
    "        info = \"## GPU не доступен\\nИспользуется CPU\"\n",
    "    \n",
    "    return info\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    info = get_gpu_info()\n",
    "    print(info)\n",
    "    \n",
    "    # Сохраняем в файл\n",
    "    with open(\"docs/gpu_info.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a3702b6-b748-4db4-899b-34cbe6bc83ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sanit\\miniconda3\\envs\\neyro\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Sanit\\miniconda3\\envs\\neyro\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Epoch 1: 100%|█████████████████████████████████████████████████████████| 1563/1563 [01:59<00:00, 13.08it/s, loss=0.144]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1  val-acc=0.944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|█████████████████████████████████████████████████████████| 1563/1563 [01:57<00:00, 13.28it/s, loss=0.371]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2  val-acc=0.948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|████████████████████████████████████████████████████████| 1563/1563 [01:58<00:00, 13.18it/s, loss=0.0368]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3  val-acc=0.949\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# 1. Импорты и проверка устройства\n",
    "# ================================================================\n",
    "import torch, torchvision, time, onnx, onnxruntime, numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "from tqdm import tqdm   # pip install tqdm\n",
    "\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# 2. Преобразования и загрузка CIFAR-10\n",
    "# ================================================================\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_ds = datasets.CIFAR10(root=\"data\", train=True,  download=True, transform=transform)\n",
    "val_ds   = datasets.CIFAR10(root=\"data\", train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True,  num_workers=2)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "model_b0 = torchvision.models.efficientnet_b0(pretrained=True)\n",
    "model_b0.classifier[1] = torch.nn.Linear(model_b0.classifier[1].in_features, 10)\n",
    "model_b0 = model_b0.to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model_b0.parameters(), lr=3e-4)\n",
    "\n",
    "def accuracy(net, loader):\n",
    "    net.eval()\n",
    "    correct = total = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            correct += (net(x).argmax(1) == y).sum().item()\n",
    "            total   += y.size(0)\n",
    "    return correct/total\n",
    "    \n",
    "for epoch in range(3):\n",
    "    model_b0.train()\n",
    "    # оборачиваем именно тренировочный loader\n",
    "    with tqdm(train_loader, desc=f\"Epoch {epoch+1}\") as pbar:\n",
    "        for x, y in pbar:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(model_b0(x), y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # обновляем строку прогресса текущим лоссом\n",
    "            pbar.set_postfix(loss=loss.item())\n",
    "    torch.save(model_b0, f\"model_b0_epochs/model_b0_epoch_{epoch + 1}.pt\")\n",
    "\n",
    "    # после эпохи — метрика\n",
    "    print(f\"Epoch {epoch+1}  val-acc={accuracy(model_b0, val_loader):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966f257e-5a7d-4c8f-a972-a4f25572c1c6",
   "metadata": {},
   "source": [
    "LATENCY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eda5880-827c-4f94-badd-daad0cc80a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "БЕЗОПАСНОЕ ИЗМЕРЕНИЕ ЛАТЕНЦИИ\n",
      "============================================================\n",
      "============================================================\n",
      "НАЧАЛО ИЗМЕРЕНИЯ ЛАТЕНЦИИ\n",
      "============================================================\n",
      "Попытка измерения на GPU...\n",
      "Warm-up...\n",
      "\n",
      "Измерение латенции (100 прогонов)...\n",
      "Прогон 1/100: 15.345 мс\n",
      "  Память GPU: 0.05 GB / 0.09 GB\n",
      "Прогон 11/100: 16.567 мс\n",
      "  Память GPU: 0.05 GB / 0.09 GB\n",
      "Прогон 21/100: 16.531 мс\n",
      "  Память GPU: 0.05 GB / 0.09 GB\n",
      "Прогон 31/100: 16.803 мс\n",
      "  Память GPU: 0.05 GB / 0.09 GB\n",
      "Прогон 41/100: 16.219 мс\n",
      "  Память GPU: 0.05 GB / 0.09 GB\n",
      "Прогон 51/100: 16.402 мс\n",
      "  Память GPU: 0.05 GB / 0.09 GB\n",
      "Прогон 61/100: 16.628 мс\n",
      "  Память GPU: 0.05 GB / 0.09 GB\n",
      "Прогон 71/100: 16.980 мс\n",
      "  Память GPU: 0.05 GB / 0.09 GB\n",
      "Прогон 81/100: 16.383 мс\n",
      "  Память GPU: 0.05 GB / 0.09 GB\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eda62fc-48e8-43ad-befc-c49c3fb4f91e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
