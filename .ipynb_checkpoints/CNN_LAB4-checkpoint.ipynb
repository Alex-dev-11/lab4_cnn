{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3124d698-62ac-47d5-b22d-f8af3e969ea1",
   "metadata": {},
   "source": [
    "# Лаборатория «PyTorch → ONNX → INT8»  \n",
    "## Курс: Компьютерное зрение, 4-й модуль  \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "##  Ячейка 0. Установка зависимостей\n",
    "\n",
    "```bash\n",
    "# Colab (GPU)\n",
    "!pip install -q torch torchvision onnxruntime-gpu tqdm onnx\n",
    "\n",
    "# Локально (CPU)\n",
    "!pip install -q torch torchvision onnx onnxruntime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1346fe-3c46-486b-bdab-2dcd66384ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 0.  Установка нужных библиотек (в Colab ставим только GPU-версию)\n",
    "# ================================================================\n",
    "# !pip install -q torch torchvision onnx onnxruntime-gpu  # Colab\n",
    "# !pip install -q torch torchvision onnx onnxruntime      # локальный CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be9e80f-6f1c-470a-8dd7-affb16a6bae9",
   "metadata": {},
   "source": [
    "## Что происходит\n",
    "\n",
    "Устанавливаем «минимальный набор» для обучения и инференса.\n",
    "\n",
    "\n",
    "## GitHub-совет\n",
    "\n",
    "Сразу заведите requirements.txt:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af4162f-55b9-40a0-a06c-5f1c7f486e83",
   "metadata": {},
   "source": [
    "torch==2.2.1\n",
    "\n",
    "torchvision==0.17.1\n",
    "\n",
    "onnx==1.16\n",
    "\n",
    "onnxruntime-gpu==1.17  # для CPU замените на onnxruntime\n",
    "\n",
    "tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762c6d77-1e2a-4489-b98b-2c010252d7e5",
   "metadata": {},
   "source": [
    "Коммитьте его в корень репозитория.\n",
    "\n",
    "## Домашнее задание 1\n",
    "\n",
    "Создайте виртуальное окружение python -m venv venv, активируйте его и установите зависимости строго по файлу. Скриншот pip freeze > freeze.txt приложите к Pull Request-у с тегом #dz0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7a7aa6-b614-4e7c-9526-9c6f066acbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 1. Импорты и проверка устройства\n",
    "# ================================================================\n",
    "import torch, torchvision, time, onnx, onnxruntime, numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72a54a5-d495-4c08-a211-3f70dbaa0565",
   "metadata": {},
   "source": [
    "ДЗ (1 ⭐)\n",
    "Выведите torch.cuda.get_device_name(0) и torch.cuda.get_device_properties(0).total_memory в Markdown-таблицу. Сохраните вывод в docs/gpu_info.md."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8824724b-202c-4752-98ee-afbc7349eaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 2. Преобразования и загрузка CIFAR-10\n",
    "# ================================================================\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_ds = datasets.CIFAR10(root=\"data\", train=True,  download=True, transform=transform)\n",
    "val_ds   = datasets.CIFAR10(root=\"data\", train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True,  num_workers=2)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=64, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2ae402-1fa7-4135-a6ac-eca1f4556e1e",
   "metadata": {},
   "source": [
    "## Пояснение\n",
    "\n",
    "Одна строчка определяет, будет ли ноутбук работать 3 минуты или 3 часа.\n",
    "\n",
    "## GitHub-совет\n",
    "\n",
    "Добавьте .gitignore:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32ec941-1169-482d-88ed-e723bafe6969",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "venv/\n",
    "__pycache__/\n",
    "*.ipynb_checkpoints/\n",
    "data/          # тяжёлый датасет не коммитим\n",
    "*.onnx\n",
    "*.pth\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c59565-a8e7-452a-b785-ee77c8683714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 3. Берём предобученную «сверхточную» модель\n",
    "#    EfficientNet-B3 даёт ≈ 84 % Top-1 на ImageNet → хороший выбор\n",
    "# ================================================================\n",
    "model = torchvision.models.efficientnet_b3(pretrained=True)\n",
    "model.classifier[1] = torch.nn.Linear(model.classifier[1].in_features, 10)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0a3301-df3e-4af6-b5da-160c947a5bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm   # pip install tqdm\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)\n",
    "\n",
    "def accuracy(net, loader):\n",
    "    net.eval()\n",
    "    correct = total = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            correct += (net(x).argmax(1) == y).sum().item()\n",
    "            total   += y.size(0)\n",
    "    return correct/total\n",
    "\n",
    "for epoch in range(3):\n",
    "    model.train()\n",
    "    # оборачиваем именно тренировочный loader\n",
    "    with tqdm(train_loader, desc=f\"Epoch {epoch+1}\") as pbar:\n",
    "        for x, y in pbar:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(model(x), y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # обновляем строку прогресса текущим лоссом\n",
    "            pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "    # после эпохи — метрика\n",
    "    print(f\"Epoch {epoch+1}  val-acc={accuracy(model, val_loader):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92603b35-47be-46e2-a9b2-36d615caa53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 7. Сравнение скорости инференса\n",
    "#    Будем прогонять 1000 батчей по 32 картинки = 32 000 изображений\n",
    "# ================================================================\n",
    "def pytorch_inference_time(net, loader, batches=1000):\n",
    "    net.eval()\n",
    "    torch.cuda.synchronize()\n",
    "    t0 = time.time()\n",
    "    with torch.no_grad():\n",
    "        for i, (x, _) in enumerate(loader):\n",
    "            if i == batches: break\n",
    "            x = x.to(device)\n",
    "            _ = net(x)\n",
    "        torch.cuda.synchronize()\n",
    "    return time.time() - t0\n",
    "\n",
    "def onnx_inference_time(sess, loader, batches=1000):\n",
    "    input_name  = sess.get_inputs()[0].name\n",
    "    torch.cuda.synchronize() if device.type==\"cuda\" else None\n",
    "    t0 = time.time()\n",
    "    for i, (x, _) in enumerate(loader):\n",
    "        if i == batches: break\n",
    "        x = x.numpy()\n",
    "        _ = sess.run(None, {input_name: x})\n",
    "    torch.cuda.synchronize() if device.type==\"cuda\" else None\n",
    "    return time.time() - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4ca08b-4cbc-4cb9-a0b5-5ddfd35ad534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7а) PyTorch\n",
    "pytorch_gpu_time = pytorch_inference_time(model, val_loader)\n",
    "print(f\"PyTorch GPU: {pytorch_gpu_time:.2f} с\")\n",
    "\n",
    "# 7б) ONNX Runtime GPU\n",
    "ort_session_gpu = onnxruntime.InferenceSession(onnx_path,\n",
    "                providers=[\"CUDAExecutionProvider\"])\n",
    "onnx_gpu_time = onnx_inference_time(ort_session_gpu, val_loader)\n",
    "print(f\"ONNX  GPU:   {onnx_gpu_time:.2f} с\")\n",
    "\n",
    "# 7в) ONNX Runtime CPU\n",
    "ort_session_cpu = onnxruntime.InferenceSession(onnx_path,\n",
    "                providers=[\"CPUExecutionProvider\"])\n",
    "onnx_cpu_time = onnx_inference_time(ort_session_cpu, val_loader)\n",
    "print(f\"ONNX  CPU:   {onnx_cpu_time:.2f} с\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70329655-e70b-43f0-b350-86e780f56e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 8. Сводная таблица\n",
    "# ================================================================\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({\n",
    "    \"Framework\": [\"PyTorch-GPU\", \"ONNX-GPU\", \"ONNX-CPU\"],\n",
    "    \"Time (s)\":  [pytorch_gpu_time, onnx_gpu_time, onnx_cpu_time],\n",
    "    \"Speed-up vs PT\": [1.,\n",
    "                       pytorch_gpu_time/onnx_gpu_time,\n",
    "                       pytorch_gpu_time/onnx_cpu_time]\n",
    "})\n",
    "print(df.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469d03ad-6f74-49c2-8667-8132ad7766a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 9. (Опционально) Квантизация в INT8 через onnxruntime\n",
    "# ================================================================\n",
    "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "quant_path = \"effnet_b3_cifar10_int8.onnx\"\n",
    "quantize_dynamic(onnx_path, quant_path, weight_type=QuantType.QUInt8)\n",
    "\n",
    "# Прогоняем ещё раз\n",
    "ort_session_int8 = onnxruntime.InferenceSession(quant_path,\n",
    "                providers=[\"CPUExecutionProvider\"])\n",
    "int8_time = onnx_inference_time(ort_session_int8, val_loader)\n",
    "print(f\"ONNX-CPU-INT8: {int8_time:.2f} с\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aab4f7c-42b4-4738-8a48-2c5c544ab259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 10. Выводы (студент дополняет своими цифрами)\n",
    "# ================================================================\n",
    "print(\"Выводы:\")\n",
    "print(\"- ONNX-GPU даёт ускорение ~1.3× по сравнению с PyTorch-GPU\")\n",
    "print(\"- INT8-квантизация ускоряет ещё в 2.5×, точность падает <0.5 %\")\n",
    "print(\"- Для продакшена выгодно использовать ONNX-runtime + GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a976709-b195-4407-b5e6-e9e0dc9bc8cc",
   "metadata": {},
   "source": [
    "Общие требования\n",
    "\n",
    "    Выполняйте задания строго в своём GitHub-репозитории.\n",
    "    Каждое задание = отдельная ветка dz/N-краткое-название + Pull Request в main.\n",
    "    В описании PR приложите скриншоты/CSV-файлы и ссылку на отчёт в docs/.\n",
    "    Максимум – 18 баллов. Для зачёта нужно ≥ 10."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83b1bdc-bdb2-4b87-b4bd-a0122dc7a933",
   "metadata": {},
   "source": [
    "| №                   | Название                                                                          | Краткое содержание                                                                                 | Баллы |\n",
    "| ------------------- | --------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------- | ----- |\n",
    "| 0                   | **requirements.txt**                                                              | Создайте файл, который ставится одной командой `pip install -r requirements.txt`. Добавьте в репо. | 1     |\n",
    "| 1                   | **GPU-отчёт**                                                                     | Выведите `torch.cuda.get_device_name(0)` и объём VRAM в `docs/gpu_info.md`.                        | 1     |\n",
    "| 2                   | **Альбументо-аугментации**                                                        | Добейтесь ≥ 87 % accuracy на CIFAR-10 за 10 эпох. Сохраните `accuracy_plot.png`.                   | 2     |\n",
    "| 3                   | **A/B EfficientNet**                                                              | Замените B3 → B0, измерьте drop точности и прирост FPS. Оформите `docs/efficientnet_ablation.md`.  | 1     |\n",
    "| 4                   | **Early Stopping**                                                                | Добавьте раннюю остановку и сохраняйте `checkpoint.tar` (веса + оптимизатор).                      | 2     |\n",
    "| 5  **Латенция-100** | Измерьте latency **одной** картинки (100 прогонов). Сохраните `docs/latency.png`. | 1                                                                                                  |       |\n",
    "| 6                   | **TensorRT**                                                                      | Подключите `TensorrtExecutionProvider`, измерьте throughput. Скриншот вывода в PR.                 | 2     |\n",
    "| 7                   | **Seaborn-barplot**                                                               | Постройте график speed-up PyTorch vs ONNX vs INT8. Сохраните `docs/speedup.png`.                   | 1     |\n",
    "| 8                   | **INT8-точность**                                                                 | Сравните Top-1 float32 vs INT8 на 1000 картинках. Напишите вывод в `docs/quantization.md`.         | 2     |\n",
    "| 9                   | **Итоговый отчёт**                                                                | Краткий PDF (200–300 слов) + графики. Загрузите в LMS и приложите ссылку на репо.                  | 3     |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb35088-4201-4f5f-ae56-19cfe80177f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
